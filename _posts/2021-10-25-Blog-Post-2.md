---
layout: post
title: PIC 16B - Blog Post 2
---

Jun Hur's Blog Post 2 for PIC 16B!

# 1. My Favorite Movie: The Butterfly Effect.

Here is the link to the movie on **IMDB** page : https://www.imdb.com/title/tt0289879/

And here is the page where I can see the **Series Cast**: https://www.imdb.com/title/tt0289879/fullcredits/

And I chose **Ashton Kutcher** here, bringing me to this page: https://www.imdb.com/name/nm0005110/

Now, I want to create a `scraper` that does this job: start from this movie, look at all the actors in the movie, and then log all the other movies or TV shows that he or she worked on.

First, I need to type the following to start on Anaconda terminal:

```python
conda activate PIC16B
scrapy startproject IMDB_scraper
cd IMDB_scraper
```

Then it will create a file called `IMDB_scraper` on the current directory. In the `settings.py` file, I add the following line to prevent my scraper from downloading too much data for now.

```python
CLOSESPIDER_PAGECOUNT = 20
```

# 2. Create a Scraper.

I will create a python file `imdb_spider.py` in the `spiders` folder and add the lines:

```python
    #our scraper!

    # name of our scraper, to be called when we crawl.
    name = 'imdb_spider'
    
    # this is the url of my favorite movie, the Butterfly Effect.
    start_urls = ['https://www.imdb.com/title/tt0289879/']
```

Here is the important part: **`parse(self,response)`** method.

This method will start on my movie and navigate to the *Cast & Crew* Page.

```python
    def parse(self,response):
        """
        Starts on the start_urls and navigates to 
        the Cast&Crew page

        Note that the Cast&Crew page has url 
        ending ~ "fullcredits/"
        """
        
        #add the "fullcredits/" to the 
        #start_url for Cast&Crew page.
        cast_crew = response.urljoin("fullcredits/")

        #yield the url, and call the next parse method.
        yield scrapy.Request(cast_crew, 
        callback = self.parse_full_credits)
```

When we call `response.urljoin("fullcredits/")` in `scrapy shell`, we see:

![_config.yml]({{ site.baseurl }}/images/blog_2_0.JPG)

This the url of the *Cast & Crew* Page!

Then, the `parse_full_credits(self, response)` method is called:

```python
    def parse_full_credits(self,response):
        """
        Assume we start on the Cast&Crew page,

        Yield a scrapy.
        Request for the page of each actor 
        listed on the page.

        Crew members are excluded.
        """
        
        #shows what to add 
        #to the previous url for each actor
        actors_urls = [
            a.attrib["href"] for a 
            in response.css("td.primary_photo a")]

        #add it to the previous url, 
        #and move to each actor's page!
        urls = [response.urljoin(a) 
            for a in actors_urls]

        #yield the url for each actor, 
        #and call the last parst method.
        for url in urls:
            yield scrapy.Request(url, 
            callback = self.parse_actor_page)
```

Let's see what's happening here.

First, when we see the `response.css("td.primary_photo a")` output in the shell, we see a large set of output:

![_config.yml]({{ site.baseurl }}/images/blog_2_1.JPG)

Note the **nm .....** in **<a href= ... >** here:

![_config.yml]({{ site.baseurl }}/images/blog_2_2.JPG)

That is what we are looking at!

Each of them is the **url of each of the actors!**

For example, the first actor on the page https://www.imdb.com/title/tt0289879/fullcredits/ is *Ashton Kutcher*, and his url is 

![_config.yml]({{ site.baseurl }}/images/blog_2_3.JPG)

So we are **to yield a `scrapy.Request` for the page of each of the actors on the page.**

Let's examine the *css structure* of the actor's page!

First, we see that **the actor's name** appears as follow:

![_config.yml]({{ site.baseurl }}/images/blog_2_4.JPG)

Second, the **Movies or TV shows** the actor has worked appears as follow:

![_config.yml]({{ site.baseurl }}/images/blog_2_5.JPG)

Let's experiment this on the shell:

![_config.yml]({{ site.baseurl }}/images/blog_2_6.JPG)

We need to extract the name, so we need to call 

![_config.yml]({{ site.baseurl }}/images/blog_2_7.JPG)

Now, extracting the movie or TV show names is more challenging, but let's see on the shell as well!

![_config.yml]({{ site.baseurl }}/images/blog_2_8.JPG)

So we can see the list of the movies or Tv shows this way:

![_config.yml]({{ site.baseurl }}/images/blog_2_9.JPG)

This is the list of **first 10 movies of TV shows** where *Ashton Kutcher has worked*.

![_config.yml]({{ site.baseurl }}/images/blog_2_10.JPG)

Looks good!

Let's transform those processes in code:

```python
    def parse_actor_page(self,response):
        """
        Assume we start on the page of an actor

        Yield a dictionary in form 
        {"actor" : actor_name,
        "movie_or_TV_name" : movie_or_TV_name}

        This is a dictionary for 
        each of the movies or TV shows
        in which the actor has worked.
        """
        # extract the name of the actor
        actor_name = response.css(
            "span.itemprop::text")[0].get()
        
        # extract the list of movies or TV shows for each actor.
        movies_or_TV_shows_names = [
            a.css("a::text").get() 
            for a in response.css("div.filmo-row")]

        #yield a dictionary for actor name and movies or TV shows.
        for item in movies_or_TV_shows_names:
            yield {
                "actor" : actor_name,
                "movie_or_TV_name": item
            }
        
```

Everything looks good!

Now let's save the results in csv file by running the command:

```python
scrapy crawl imdb_spider -o results.csv
```

Now we have an excel file containing **the actor's name and the names of movies or TV shows that the actor appears.**

![_config.yml]({{ site.baseurl }}/images/blog_2_11.JPG)

In the `settings.py` file, we will comment out the line

`CLOSESPIDER_PAGECOUNT = 20`

and run the command again.

# Conclusion

Using **Jupyter Notebook**, let's create a table for a **list of movies** with the most shared actors from *the Butterfly Effect*.

Let's bring the results to code:

```python
import pandas as pd

#bring the results
results = pd.read_csv("results.csv")
results
```

![_config.yml]({{ site.baseurl }}/images/blog_2_code_0.JPG)

Let's create a dictionary for counting, and **add each item into the dictionary by counting in the column**

```python
count = {}
for item in results["movie_or_TV_name"]:
    if item in count.keys():
        count[item] += 1
    
    else:
        count[item] = 1

```

This will give us `items()` in the `count` dictionary.

![_config.yml]({{ site.baseurl }}/images/blog_2_code_1.JPG)

Let's convert it to a dataframe!

```python
df_shared_actors = pd.DataFrame(count.items())
df_shared_actors
```

![_config.yml]({{ site.baseurl }}/images/blog_2_code_2.JPG)

We are going to change the column names to sort:

```python
df_shared_actors.columns = ["Movie","number of shared actors"]
df_shared_actors
```
![_config.yml]({{ site.baseurl }}/images/blog_2_code_3.JPG)

Let's sort it by `number of shared actors` column and note the index should be reset.

```python
df_shared_actors_sorted = df_shared_actors.sort_values(
    by = ["number of shared actors"], ascending = False)

df_shared_actors_sorted
```
![_config.yml]({{ site.baseurl }}/images/blog_2_code_4.JPG)

```python
df_shared_actors_sorted.reset_index(drop=True)
```
![_config.yml]({{ site.baseurl }}/images/blog_2_code_5.JPG)

Here is the table for a list of **movies that share same actors as in the Butterfly Effect**.

Of course, the movie itself shares the most actor, and we can see about 1/3 of the actors appear on the second movie, **Smallville**. 


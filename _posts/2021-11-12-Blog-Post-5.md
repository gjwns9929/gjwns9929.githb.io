---
layout: post
title: PIC 16B - Blog Post 5

---

Jun Hur's Blog Post 5 for PIC 16B!

# Image Classification In Tensorflow

Today we are interested in teaching a machine learning algorithm to distinguish between pictures of dogs and cats.

The complete instruction can be found <a href="https://www.philchodrow.com/PIC16B//posts/blog-post-5"> here </a>. 


# 1.Load Packages and Obtain Data

![_config.yml]({{ site.baseurl }}/images/blog_5_1_0.JPG)

By running the following code, we create TensorFlow `Dataset`s for training, validation, and testing.

Again, from **Blog Post 1** we did the other day, we can use data sets in cases where it's not practical to load all the data into memory.

Using `image_dataset_from_directory` in `keras` `utils`, we specify that

- the images will be located in `train_dir` or `validation_dir`
- the data will be random by `shuffle=True`
- 32 images will be loaded in each of the data sets by `batch_size = BATCH_SIZE`
- the size of image will be 160 x 160 by `image_size = IMG_SIZE`

Additionally, the following code is for rapid reading:

![_config.yml]({{ site.baseurl }}/images/blog_5_1_1.JPG)

## Working with Datasets

Finally, we can get a piece of a data set using the `take` method. 

Here, we will **write a function to create a two-row visualization**.
More specifically, the first row shows three random pictures of **cats** and the second row shows three random pictures of **dogs**

This will be a hint:
- The following code creates an *iterator* called `labels`.
![_config.yml]({{ site.baseurl }}/images/blog_5_1_2.JPG)
- And, by referring to this <a href="https://www.tensorflow.org/tutorials/images/transfer_learning"> site, </a> the following code will show **3x3 images and labels from the training set**. 
![_config.yml]({{ site.baseurl }}/images/blog_5_1_3.JPG)
![_config.yml]({{ site.baseurl }}/images/blog_5_1_4.JPG)

To **compute the number of images** in the training data with label `0` or `cats` and `1` or `dogs`, we come back to our iterator defined above:

![_config.yml]({{ site.baseurl }}/images/blog_5_1_5.JPG)

We have 1000 cats and dogs. Therefore, the *baseline* is **0.5, or 50%**

# 2.First Model

For our first model, we will use `tf.keras.Sequential` model using `layers` discussed in class, especially <a href="https://colab.research.google.com/github/PhilChodrow/PIC16B/blob/master/lectures/tf/tf-2.ipynb#scrollTo=infinite-installation"> here </a>. 

More specifically, in each model, we will include:

- at least **two** `Conv2D` layers
- at least **two** `MaxPooling2D` layers
- at least **one** `Flatten` layer
- at least **one** `Dense` layer

Lastly, to train our model, we will 

```python
history = model1.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

For our first model, I aim to do a **bit better** than the baseline, so **at least 52% validation accuracy**.

![_config.yml]({{ site.baseurl }}/images/blog_5_2_0.JPG)
![_config.yml]({{ site.baseurl }}/images/blog_5_2_1.JPG)

## Assessment
- First, the accuracy of the first model stabilized **between 52% and 61%** during training. We achieved our goal of at least 52%!
- Considering that the baseline was 50%, this is definitely better.
- However, we see **clear Overfitting**. That is, we have **100%** training accuracy while the validation accuracy is about 60%. We need to come up with a better model.

Before we move on, I would like to look at the learning curves of the training and validation accuracy/loss. Refer <a href="https://www.tensorflow.org/tutorials/images/transfer_learning"> here </a> for more information.

![_config.yml]({{ site.baseurl }}/images/blog_5_2_2.JPG)
![_config.yml]({{ site.baseurl }}/images/blog_5_2_3.JPG)

As we expected, severe overfitting. 

# 3. Model with Data Augmentation
We are going to add some *data augmentation* to our model.

- First, we will create a `tf.keras.layers.RandomFlip()` layer. This will show a flipped with `RandomFlip`. The documentation is also <a href="https://www.tensorflow.org/tutorials/images/transfer_learning"> here </a>.

- Next, we will create a `tf.keras.layers.RandomRotation()` layer. This will show a rotated with `RandomRotation()`. The documentation is also <a href="https://www.tensorflow.org/tutorials/images/transfer_learning"> here </a>.

## Flip
![_config.yml]({{ site.baseurl }}/images/blog_5_3_0.JPG)

## Rotation
![_config.yml]({{ site.baseurl }}/images/blog_5_3_1.JPG)

## Enhance the model

![_config.yml]({{ site.baseurl }}/images/blog_5_3_2.JPG)
![_config.yml]({{ site.baseurl }}/images/blog_5_3_3.JPG)


Here, we added `RandomFlip()` and `RandomRotation()` layers, and kept almost other layers the same. 

**NOTE**: I applied 0.05 for dropOut value for optimization purpose.

As a result, we see a similar set of values for validation accuracy, converging to around **60%**. 
**Great**!

Also, we have the training accuracy value drop to around 65% also, which is a great point as well, we have much less overfitting this time.

Don't forget the history plot!
![_config.yml]({{ site.baseurl }}/images/blog_5_3_4.JPG)

This plot shows a great improvement from `model1`

# 4. Data Preprocessing
Next, we will make some transformations to the input data. The following code will create a preprocessing layer called `preprocessor`, which we will use for our new model.

![_config.yml]({{ site.baseurl }}/images/blog_5_4_0.JPG)
![_config.yml]({{ site.baseurl }}/images/blog_5_4_1.JPG)
![_config.yml]({{ site.baseurl }}/images/blog_5_4_2.JPG)



This `model3` has validation accuracy values converging to **at least 70%**!. This is a significant jump from model1.

![_config.yml]({{ site.baseurl }}/images/blog_5_4_3.JPG)

In terms of overfitting, it is getting **better**, as the training accuracy is getting closer to validation accuracy.

# 5. Transfer Learning

The idea of this part is that there might be (probably very likely) a pre-existing model for image classification. How could we use a pre-existing model for this project?

First, we will access a pre-existing model, incorporate it into a full model, train the model, and evaluate it.

The following code will download `MobileNetV2` and we will obtain a layer that we will use for our new model.

![_config.yml]({{ site.baseurl }}/images/blog_5_5_0.JPG)

In summary, we will use layers that
- `preprocessor` layer from **Data Preprocessing** part
- `flip` and `rotation` layers from **Data Augmentation** part
- `base_model_layer` we just created
- `Dense(2)` layer

![_config.yml]({{ site.baseurl }}/images/blog_5_5_1.JPG)
![_config.yml]({{ site.baseurl }}/images/blog_5_5_2.JPG)


As we can see in the code, most of `layers` between `base_model_layer` and `Dense(2)` are not necessary. Rather, I added `GlobalMaxPooling2D` and kept `Dropout` layer. 

We can see why here, using `model4.summary()`.
![_config.yml]({{ site.baseurl }}/images/blog_5_5_3.JPG)

There is a lot of complexity hidden in this model, with more than 2 million non-trainable parameters. This is a lot to train.

As a result, we see an incredible set of validation accuracy, at least **95%**.

This is also a huge jump from `model3`, which had validation accuracy values converging to only 70%.

In terms of overfitting, we should **NOT** be too much worried about it as the training and validation accuracy values are not greatly different. 

# 6. Score on Test Data

Lastly, we will simply evaluate our model. As we saw, `model4` perform the best. Therefore, we will simply use `model4.evaluate(test_dataset)` to find the **loss** and **accuracy** value.

![_config.yml]({{ site.baseurl }}/images/blog_5_6_0.JPG)

We see a very low loss value of **0.04** and very high accuracy of **0.99**.

Awesome!
